# 百万级数据迁移、汇总

最近在工作中，需要对一些数据表的数据进行迁移及汇总，所以总结下自己遇到的问题及解决方案。
[data-segmenter](https://packagist.org/packages/alanalbert/data-segmenter)

<!-- more -->

## 一、数据迁移

对百万级数据进行数据迁移。

### 1. 问题

在进行迁移过程中，因为数据量比较大，且存在内存限制，因此将所有数据一次全部取出来是肯定不行的。那如何进行数据迁移呢？

### 2. 解决方法

既然一次装不下所有数据，那就使用**分段的形式**来依次读取。

* 说到分段读取，最先想到的就是使用MySQL提供的分段方式 `limit m,n` 来读取数据。

> 但是使用`limit m,n`进行分段取数据，MySQL需要首先计算出m行数据，然后往后取n条。因此当m值越大，查询速度就会越慢。

* 另外一种方式，用`where`条件查询来查询数据，进而让MySQL使用到索引。

> 每个数据表都会有一个自增ID，我们可以使用这个自增ID作为条件判断。每次取出数据后，都记录上次最后一行记录的ID，以作为下次取数据的判断依据。例如：
> 
> ```sql
> SELECT * FROM `test` WHERE id>2000 LIMIT 1000;
> ```
> 
> 其中，2000就是上一次取出的数据中的最大ID。

由此，我基于illuminate/database编写了一个类似于分页器的数据读取组件：[data-segmenter](https://packagist.org/packages/alanalbert/data-segmenter).

具体实现代码如下：

```php
use AlanAlbert\Segmenter\Contract\Processor;
use Illuminate\Database\Eloquent\Model;
use \Exception;
use Illuminate\Database\Eloquent\Builder;
class Segmenter
{
    const ALL_ROWS = -1;
    
    /**
     * 源模型
     * @var array
     */
    protected $sourceModel = null;
    
    /**
     * 保存每个模型的最后一行主键id
     * @var int
     */
    private $lastRowId = -1;
    
    /**
     *模型中最大的ID
     * @var int
     */
    private $maxRowId = 0;
    
    /**
     * 一次处理的数据量
     * @var int
     */
    private $oneTimeRowNumber = -1;
    
    /**
     * 用于记录行数的列名（保证其在源模型中唯一性及递增性）
     * @var string
     */
    private $mainField = '';
    
    /**
     * 需要获取的列
     * @var array|mixed
     */
    private $fields = [];
    
    /**
     * 数据表的别名
     * @var mixed|string
     */
    private $as = '';
    
    /**
     * Segmenter构造函数
     *
     * @param Model|Builder $sourceModel
     * @param array $config
     *   配置的结构：
     *      [
     *          rows_number: 一次读取数据行数,
     *          main_field: 根据哪一列进行分段，默认取主键ID,
     *          fields: 需要获取的数据列,
     *          table_alias: 表的别名
     *      ]
     * 
     */
    public function __construct($sourceModel, array $config = [])
    {
        $this->sourceModel = $sourceModel;
        $this->oneTimeRowNumber = $config['rows_number'] ?? self::ALL_ROWS;
        // 设置main_field
        if (isset($config['main_field']) && !empty($config['main_field'])) {
            $this->mainField = $config['main_field'];
        } else {
            $this->mainField = $sourceModel instanceof Model ?
                $sourceModel->newInstance()->getKeyName() : 
                $sourceModel->newModelInstance()->getKeyName();
        }
        // 设置fields
        $this->fields = $config['fields'] ?? [];
        // 设置表别名
        $tableName = $sourceModel instanceof Model ?
            $sourceModel->newInstance()->getTable() : 
            $sourceModel->newModelInstance()->getTable();
        $this->as = $config['table_alias'] ?? $tableName;
        // 获取最大ID
        $maxRowId = (clone $sourceModel)
            ->orderByDesc($this->as . '.' . $this->mainField)
            ->limit(1)
            ->value($this->mainField);
        $this->maxRowId = $maxRowId ?? 0;
        var_dump('最大ID: ' . $this->maxRowId);
    }
    
    /**
     * 迁移数据
     * @param Processor $processor 实现DataProcessor接口，主要处理读出后的数据
     * @param mixed ...$args 额外需要使用的参数
     * @return bool
     */
    public function execute(Processor $processor, ...$args): bool
    {
        // 循环读取数据，直至结尾
        while ($this->lastRowId < $this->maxRowId) {
            if ($this->executeOneTime($processor, ...$args) === false) {
                return false;
            }
        }
    
        return true;
    }
    
    /**
     * 
     * @param Processor $processor
     * @param mixed ...$args
     * @return bool
     */
    protected function executeOneTime(Processor $processor, ...$args): bool
    {
        // 获取原始数据
        $sourceModel = $this->sourceModel
            ->where($this->as . '.' . $this->mainField, '>', $this->lastRowId)
            ->orderBy($this->as . '.' . $this->mainField);
        if ($this->oneTimeRowNumber > 0) {
            $sourceModel = $sourceModel
                ->limit($this->oneTimeRowNumber);
        }
        if (!empty($this->fields)) {
            $sourceData = $sourceModel
                ->get(array_merge($this->fields, [$this->as . '.' . $this->mainField]));
        } else {
            $sourceData = $sourceModel
                ->get();
        }
        
        // 更新当前ID
        $mainField = $this->mainField;
        $this->lastRowId = $sourceData->last()->$mainField;
        var_dump('当前ID: ' . $this->lastRowId . '/' . $this->maxRowId);
        return $processor->process($sourceData, ...$args);
    }
}
```

*虽然最后工作中也没用到...*

## 二、数据汇总

对百万级数据进行分组汇总，举个简单的例子：统计出连锁网吧的用户数。

### 1. 问题

如果选课表为`user_log`，网吧ID为`bar_id`，用户ID为`user_id`。统计的SQL语句可以为：

```SQL
SELECT COUNT(DISTINCT `bar_id`, `user_id`) AS `user_number` 
  FROM `user_log`;
```

但是这样存在一个问题：汇总的速度很慢，脚本运行时间需要用到**一分半钟**，这对于10分钟执行一次的脚本来说，时间有点长，如何优化呢？

### 2. 解决方法

使用临时表：

1. 首先对表中的数据进行`group by`多列分组，将得到的结果作为临时表
2. 对临时表中的数据进行统计

例如：

```sql
SELECT `bar_id`, COUNT(`bar_id`) AS `user_number`
  FROM (SELECT `bar_id` FROM `user_log` GROUP BY `bar_id`, `user_id`)
  GROUP BY `bar_id`;
```

## 三、其他问题

当插入或更新的数据行很多时，出现占位符过多的的问题：`Prepared statement contains too many placeholders`。

> 这是因为MySQL支持的占位符有数量限制（2^16 - 1），因此，可以使用`array_chunk`函数对需要的数据进行分块处理，然后依次插入。
